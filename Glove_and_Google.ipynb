{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Enunciado</th>\n",
       "      <th>Tópico</th>\n",
       "      <th>Contexto</th>\n",
       "      <th>English</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>994</td>\n",
       "      <td>Meu primeiro programa\\nEscreva um programa que...</td>\n",
       "      <td>Ambientação</td>\n",
       "      <td>Outros</td>\n",
       "      <td>\"My first show Write a program that prints the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>996</td>\n",
       "      <td>Impressão de caracteres na tela\\nEscreva um pr...</td>\n",
       "      <td>Ambientação</td>\n",
       "      <td>Outros</td>\n",
       "      <td>Screen character printing Write a program tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>999</td>\n",
       "      <td>Impressão de caracteres na tela (Bart Simpson)...</td>\n",
       "      <td>Ambientação</td>\n",
       "      <td>Outros</td>\n",
       "      <td>Screen Character Printing (Bart Simpson) Writ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000</td>\n",
       "      <td>Operadores aritméticos\\nQual o valor de X para...</td>\n",
       "      <td>Ambientação</td>\n",
       "      <td>Matemático</td>\n",
       "      <td>Arithmetic Operators What is the value of X s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>578</td>\n",
       "      <td>Operadores aritméticos \\nQual o valor de Y par...</td>\n",
       "      <td>Ambientação</td>\n",
       "      <td>Matemático</td>\n",
       "      <td>Arithmetic Operators What is the value of Y s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Id                                          Enunciado       Tópico  \\\n",
       "0   994  Meu primeiro programa\\nEscreva um programa que...  Ambientação   \n",
       "1   996  Impressão de caracteres na tela\\nEscreva um pr...  Ambientação   \n",
       "2   999  Impressão de caracteres na tela (Bart Simpson)...  Ambientação   \n",
       "3  1000  Operadores aritméticos\\nQual o valor de X para...  Ambientação   \n",
       "4   578  Operadores aritméticos \\nQual o valor de Y par...  Ambientação   \n",
       "\n",
       "     Contexto                                            English  \n",
       "0      Outros  \"My first show Write a program that prints the...  \n",
       "1      Outros   Screen character printing Write a program tha...  \n",
       "2      Outros   Screen Character Printing (Bart Simpson) Writ...  \n",
       "3  Matemático   Arithmetic Operators What is the value of X s...  \n",
       "4  Matemático   Arithmetic Operators What is the value of Y s...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"../new_data.csv\")\n",
    "df.English = df.English.str.replace('\\n', ' ')\n",
    "df=df.dropna(axis=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "contador=0\n",
    "lista=[]\n",
    "while(contador<len(df['English'])):\n",
    "    if(df['Contexto'][contador]=='Outros'):\n",
    "        lista+=[contador]\n",
    "    contador+=1\n",
    "df=df.drop(lista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "master=[]\n",
    "for elemento in df['English']:\n",
    "    doc=nlp(elemento)\n",
    "    lista=[]\n",
    "    for token in doc:\n",
    "        if(token.text not in nlp.Defaults.stop_words and token.lemma_ not in nlp.Defaults.stop_words and token.text.isalpha()):\n",
    "            lista+=[token.lemma_]\n",
    "    master+=[' '.join(lista)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokens']=master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['tokens'].values\n",
    "y = df['Contexto'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GloveVectorizer:\n",
    "    def __init__(self):\n",
    "        # load in pre-trained word vectors\n",
    "        print('Loading word vectors...')\n",
    "        word2vec = {}\n",
    "        embedding = []\n",
    "        idx2word = []\n",
    "        with open('../../../../cursos/pln/novo_pln_deep-learning/nlp_class2/myCodes/glove/glove.6B.300d.txt') as f:\n",
    "            # is just a space-separated text file in the format:\n",
    "            # word vec[0] vec[1] vec[2] ...\n",
    "            for line in f:\n",
    "                values = line.split()\n",
    "                word = values[0]\n",
    "                vec = np.asarray(values[1:], dtype='float32')\n",
    "                word2vec[word] = vec\n",
    "                embedding.append(vec)\n",
    "                idx2word.append(word)\n",
    "        print('Found %s word vectors.' % len(word2vec))\n",
    "\n",
    "        # save for later\n",
    "        self.word2vec = word2vec\n",
    "        self.embedding = np.array(embedding)\n",
    "        self.word2idx = {v:k for k,v in enumerate(idx2word)}\n",
    "        self.V, self.D = self.embedding.shape\n",
    "\n",
    "    def fit(self, data):\n",
    "        pass\n",
    "\n",
    "    def transform(self, data):\n",
    "        X = np.zeros((len(data), self.D))\n",
    "        n = 0\n",
    "        emptycount = 0\n",
    "        for sentence in data:\n",
    "            tokens = sentence.lower().split()\n",
    "            vecs = []\n",
    "            for word in tokens:\n",
    "                if word in self.word2vec:\n",
    "                    vec = self.word2vec[word]\n",
    "                    vecs.append(vec)\n",
    "            if len(vecs) > 0:\n",
    "                vecs = np.array(vecs)\n",
    "                X[n] = vecs.mean(axis=0)\n",
    "            else:\n",
    "                emptycount += 1\n",
    "            n += 1\n",
    "        print(\"Numer of samples with no words found: %s / %s\" % (emptycount, len(data)))\n",
    "        return X\n",
    "\n",
    "    def fit_transform(self, data):\n",
    "        self.fit(data)\n",
    "        return self.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "class Word2VecVectorizer:\n",
    "    def __init__(self):\n",
    "        print(\"Loading in word vectors...\")\n",
    "        self.word_vectors = KeyedVectors.load_word2vec_format('../../../../cursos/pln/novo_pln_deep-learning/nlp_class2/myCodes/google/GoogleNews-vectors-negative300.bin',binary=True)\n",
    "        print(\"Finished loading in word vectors\")\n",
    "\n",
    "    def fit(self, data):\n",
    "        pass\n",
    "\n",
    "    def transform(self, data):\n",
    "        # determine the dimensionality of vectors\n",
    "        v = self.word_vectors.get_vector('king')\n",
    "        self.D = v.shape[0]\n",
    "\n",
    "        X = np.zeros((len(data), self.D))\n",
    "        n = 0\n",
    "        emptycount = 0\n",
    "        for sentence in data:\n",
    "            tokens = sentence.split()\n",
    "            vecs = []\n",
    "            m = 0\n",
    "            for word in tokens:\n",
    "                try:\n",
    "                    # throws KeyError if word not found\n",
    "                    vec = self.word_vectors.get_vector(word)\n",
    "                    vecs.append(vec)\n",
    "                    m += 1\n",
    "                except KeyError:\n",
    "                    pass\n",
    "            if len(vecs) > 0:\n",
    "                vecs = np.array(vecs)\n",
    "                X[n] = vecs.mean(axis=0)\n",
    "            else:\n",
    "                emptycount += 1\n",
    "            n += 1\n",
    "        print(\"Numer of samples with no words found: %s / %s\" % (emptycount, len(data)))\n",
    "        return X\n",
    "\n",
    "\n",
    "    def fit_transform(self, data):\n",
    "        self.fit(data)\n",
    "        return self.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading in word vectors...\n",
      "Finished loading in word vectors\n"
     ]
    }
   ],
   "source": [
    "##Professor, aqui é a escolha do tokenizer, o restante segue igual para os dois\n",
    "\n",
    "# vectorizer = GloveVectorizer()\n",
    "vectorizer = Word2VecVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samuel/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 5 members, which is less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "vetor_X_train=[]\n",
    "vetor_y_train=[]\n",
    "vetor_X_test=[]\n",
    "vetor_y_test=[]\n",
    "split = StratifiedKFold(n_splits=10, random_state=42, shuffle=True)\n",
    "for train_index, val_index in split.split(X, y):\n",
    "    vetor_X_train+=[X[train_index]]\n",
    "    vetor_X_test+=[X[val_index]]\n",
    "    vetor_y_train+=[y[train_index]]\n",
    "    vetor_y_test+=[y[val_index]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numer of samples with no words found: 0 / 887\n",
      "Numer of samples with no words found: 0 / 99\n",
      "Numer of samples with no words found: 0 / 887\n",
      "Numer of samples with no words found: 0 / 99\n",
      "Numer of samples with no words found: 0 / 887\n",
      "Numer of samples with no words found: 0 / 99\n",
      "Numer of samples with no words found: 0 / 887\n",
      "Numer of samples with no words found: 0 / 99\n",
      "Numer of samples with no words found: 0 / 887\n",
      "Numer of samples with no words found: 0 / 99\n",
      "Numer of samples with no words found: 0 / 887\n",
      "Numer of samples with no words found: 0 / 99\n",
      "Numer of samples with no words found: 0 / 888\n",
      "Numer of samples with no words found: 0 / 98\n",
      "Numer of samples with no words found: 0 / 888\n",
      "Numer of samples with no words found: 0 / 98\n",
      "Numer of samples with no words found: 0 / 888\n",
      "Numer of samples with no words found: 0 / 98\n",
      "Numer of samples with no words found: 0 / 888\n",
      "Numer of samples with no words found: 0 / 98\n"
     ]
    }
   ],
   "source": [
    "contador=0\n",
    "predictions=[]\n",
    "while(contador<len(vetor_X_train)):\n",
    "    X_train=vetor_X_train[contador]\n",
    "    y_train=vetor_y_train[contador]\n",
    "    X_test=vetor_X_test[contador]\n",
    "    y_test=vetor_y_test[contador]\n",
    "    \n",
    "    X_train = vectorizer.fit_transform(X_train)\n",
    "    estimator = SVC(kernel='rbf')\n",
    "    estimator.fit(X_train, y_train)\n",
    "    y_pred = estimator.predict(vectorizer.fit_transform(X_test))\n",
    "    predictions+=[y_pred]\n",
    "\n",
    "    contador+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=[]\n",
    "for lista1 in predictions:\n",
    "    for elemento1 in lista1:\n",
    "        y_pred+=[elemento1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_sla=[]\n",
    "for lista2 in vetor_y_test:\n",
    "    for elemento2 in lista2:\n",
    "        y_test_sla+=[elemento2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 32   2   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0\n",
      "    0   0   0   0   0]\n",
      " [  3 113   0   0   0   1   0   0   0   0   0   1   1   0   0   0   0   0\n",
      "    0   0   0   0   1]\n",
      " [  0   2   0   0   0   0   0   0   0   0   0   0   4   0   0   0   0   0\n",
      "    0   0   0   0   0]\n",
      " [  0   5   0  11   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0]\n",
      " [  0   4   0   0  15   0   0   0   0   0   0   1   1   0   0   0   0   0\n",
      "    0   0   0   0   0]\n",
      " [  0   0   0   0   2  73   0   0   0   1   0   0   3   0   0   0   0   0\n",
      "    0   0   0   0   0]\n",
      " [  0   0   0   0   2   0  40   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  29   0   0   0   0   1   0   0   0   0   0\n",
      "    0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  31   0   0   1   3   0   0   0   0   0\n",
      "    0   0   0   0   1]\n",
      " [  0   0   0   0   0   0   0   1   0   8   0   1   1   0   0   0   0   0\n",
      "    0   0   0   0   0]\n",
      " [  0   1   0   0   0   0   0   0   0   0   4   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0]\n",
      " [  4   3   0   0   0   0   0   0   2   0   0  84   3   0   0   0   0   0\n",
      "    0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0 261   0   0   0   0   0\n",
      "    0   0   0   0   0]\n",
      " [  0   2   0   0   0   0   0   0   0   0   0   0   0  16   0   0   0   0\n",
      "    0   0   0   0   0]\n",
      " [  0   1   0   0   0   1   0   0   0   0   0   0   2   0  14   0   0   0\n",
      "    0   0   0   0   0]\n",
      " [  0   1   0   0   0   0   0   0   0   0   0   0   1   0   0  20   0   0\n",
      "    0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   2   0   0   0   0  23   0\n",
      "    0   0   0   0   0]\n",
      " [  0   6   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0\n",
      "    0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   2   1   0   0   0   0   0\n",
      "   20   0   0   0   0]\n",
      " [  2   5   0   0   2   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0  26   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   3   0\n",
      "    0   0  14   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0  20   0]\n",
      " [  0   3   0   0   1   0   0   0   0   0   0   0   4   0   0   0   0   0\n",
      "    0   0   0   0  35]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(y_test_sla,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "       Bancário       0.78      0.91      0.84        35\n",
      "      Comercial       0.76      0.94      0.84       120\n",
      "  Computacional       0.00      0.00      0.00         6\n",
      "        Consumo       1.00      0.69      0.81        16\n",
      "    Data e hora       0.68      0.71      0.70        21\n",
      "        Escolar       0.97      0.92      0.95        79\n",
      "        Esporte       1.00      0.95      0.98        42\n",
      "Filmes e séries       0.97      0.97      0.97        30\n",
      "         Física       0.94      0.86      0.90        36\n",
      "      Geografia       0.89      0.73      0.80        11\n",
      "        Imposto       1.00      0.80      0.89         5\n",
      "          Jogos       0.91      0.88      0.89        96\n",
      "     Matemático       0.91      1.00      0.95       261\n",
      "  Meio ambiente       1.00      0.89      0.94        18\n",
      "       Pesquisa       1.00      0.78      0.88        18\n",
      "         Pessoa       1.00      0.91      0.95        22\n",
      "      População       0.88      0.92      0.90        25\n",
      "       Produção       0.00      0.00      0.00         7\n",
      "        Química       1.00      0.87      0.93        23\n",
      "             RH       1.00      0.74      0.85        35\n",
      "          Saúde       1.00      0.82      0.90        17\n",
      "      Segurança       1.00      1.00      1.00        20\n",
      "       Trânsito       0.95      0.81      0.88        43\n",
      "\n",
      "       accuracy                           0.90       986\n",
      "      macro avg       0.85      0.79      0.82       986\n",
      "   weighted avg       0.90      0.90      0.90       986\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samuel/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test_sla,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9016227180527383\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(y_test_sla,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('ytrue_W2V+SVC_Context-Others', y_test_sla, fmt='%s')\n",
    "np.savetxt('ypred_W2V+SVC_Context-Others', y_pred, fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noOthers(df):\n",
    "    contador=0\n",
    "    lista=[]\n",
    "    while(contador<len(df['English'])):\n",
    "        if(df['Contexto'][contador]=='Outros'):\n",
    "            lista+=[contador]\n",
    "        contador+=1\n",
    "    return df.drop(lista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Aqui eu pego os dados com parafrase, esses dados ja estão com o pre-processamento\n",
    "dfs_train = []\n",
    "dfs_test = []\n",
    "for i in range(0, 10):\n",
    "    df_train = pd.read_csv('../dadosParafrase/treino'+str(i+1)+'.csv')\n",
    "    df_train=noOthers(df_train)\n",
    "    dfs_train.append(df_train)\n",
    "    df_test = pd.read_csv('../dadosParafrase/teste'+str(i+1)+'.csv')\n",
    "    df_test=noOthers(df_test)\n",
    "    dfs_test.append(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numer of samples with no words found: 0 / 2870\n",
      "Numer of samples with no words found: 0 / 99\n",
      "Numer of samples with no words found: 0 / 2875\n",
      "Numer of samples with no words found: 0 / 99\n",
      "Numer of samples with no words found: 0 / 2875\n",
      "Numer of samples with no words found: 0 / 99\n",
      "Numer of samples with no words found: 0 / 2875\n",
      "Numer of samples with no words found: 0 / 99\n",
      "Numer of samples with no words found: 0 / 2875\n",
      "Numer of samples with no words found: 0 / 99\n",
      "Numer of samples with no words found: 0 / 2880\n",
      "Numer of samples with no words found: 0 / 98\n",
      "Numer of samples with no words found: 0 / 2880\n",
      "Numer of samples with no words found: 0 / 98\n",
      "Numer of samples with no words found: 0 / 2875\n",
      "Numer of samples with no words found: 0 / 98\n",
      "Numer of samples with no words found: 0 / 2875\n",
      "Numer of samples with no words found: 0 / 98\n",
      "Numer of samples with no words found: 0 / 2866\n",
      "Numer of samples with no words found: 0 / 99\n"
     ]
    }
   ],
   "source": [
    "contador=0\n",
    "predictions=[]\n",
    "vetor_y_test=[]\n",
    "while(contador<len(dfs_train)):\n",
    "    X_train=dfs_train[contador]['master'].values\n",
    "    y_train=dfs_train[contador]['Contexto'].values\n",
    "    X_test=dfs_test[contador]['master'].values\n",
    "    vetor_y_test+=[dfs_test[contador]['Contexto'].values]\n",
    "        \n",
    "    X_train = vectorizer.fit_transform(X_train)\n",
    "    estimator = SVC(kernel='rbf')\n",
    "    estimator.fit(X_train, y_train)\n",
    "    y_pred = estimator.predict(vectorizer.fit_transform(X_test))\n",
    "    predictions+=[y_pred]\n",
    "\n",
    "    contador+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=[]\n",
    "for lista1 in predictions:\n",
    "    for elemento1 in lista1:\n",
    "        y_pred+=[elemento1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_sla=[]\n",
    "for lista2 in vetor_y_test:\n",
    "    for elemento2 in lista2:\n",
    "        y_test_sla+=[elemento2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 32   2   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0\n",
      "    0   0   0   0   0]\n",
      " [  3 112   0   0   0   1   0   0   0   0   0   1   1   0   0   0   0   0\n",
      "    0   0   0   0   2]\n",
      " [  0   0   6   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0]\n",
      " [  0   1   0  15   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0]\n",
      " [  0   1   0   0  18   0   0   0   0   0   0   0   1   0   0   0   0   0\n",
      "    0   0   0   0   1]\n",
      " [  0   0   0   0   1  73   1   0   0   1   0   0   3   0   0   0   0   0\n",
      "    0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  42   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  30   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  34   0   0   1   0   0   0   0   0   0\n",
      "    0   0   0   0   1]\n",
      " [  0   0   0   0   0   0   0   1   0   9   0   0   1   0   0   0   0   0\n",
      "    0   0   0   0   0]\n",
      " [  0   1   0   0   0   0   0   0   0   0   4   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0]\n",
      " [  4   2   0   0   0   0   1   1   2   0   0  85   1   0   0   0   0   0\n",
      "    0   0   0   0   0]\n",
      " [  0   1   0   0   0   0   0   0   0   1   0   0 259   0   0   0   0   0\n",
      "    0   0   0   0   0]\n",
      " [  0   2   0   0   0   0   0   0   0   0   0   0   0  16   0   0   0   0\n",
      "    0   0   0   0   0]\n",
      " [  0   1   0   0   0   1   0   0   0   0   0   0   0   0  16   0   0   0\n",
      "    0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   1   0   0   0  21   0   0\n",
      "    0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  25   0\n",
      "    0   0   0   0   0]\n",
      " [  0   2   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   4\n",
      "    0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0\n",
      "   22   0   0   0   0]\n",
      " [  0   3   0   0   2   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0  30   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0\n",
      "    0   0  16   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0  20   0]\n",
      " [  0   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0  41]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(y_test_sla,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "       Bancário       0.82      0.91      0.86        35\n",
      "      Comercial       0.86      0.93      0.90       120\n",
      "  Computacional       1.00      1.00      1.00         6\n",
      "        Consumo       1.00      0.94      0.97        16\n",
      "    Data e hora       0.86      0.86      0.86        21\n",
      "        Escolar       0.97      0.92      0.95        79\n",
      "        Esporte       0.95      1.00      0.98        42\n",
      "Filmes e séries       0.94      1.00      0.97        30\n",
      "         Física       0.94      0.94      0.94        36\n",
      "      Geografia       0.82      0.82      0.82        11\n",
      "        Imposto       1.00      0.80      0.89         5\n",
      "          Jogos       0.97      0.89      0.92        96\n",
      "     Matemático       0.96      0.99      0.98       261\n",
      "  Meio ambiente       1.00      0.89      0.94        18\n",
      "       Pesquisa       1.00      0.89      0.94        18\n",
      "         Pessoa       1.00      0.95      0.98        22\n",
      "      População       0.96      1.00      0.98        25\n",
      "       Produção       1.00      0.57      0.73         7\n",
      "        Química       1.00      0.96      0.98        23\n",
      "             RH       1.00      0.86      0.92        35\n",
      "          Saúde       1.00      0.94      0.97        17\n",
      "      Segurança       1.00      1.00      1.00        20\n",
      "       Trânsito       0.91      0.95      0.93        43\n",
      "\n",
      "       accuracy                           0.94       986\n",
      "      macro avg       0.96      0.91      0.93       986\n",
      "   weighted avg       0.95      0.94      0.94       986\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test_sla,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9432048681541582\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(y_test_sla,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test_sla' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-91-9f38bcb0d51f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavetxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ytrue_W2V+GaussianNB_Context-Others'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_sla\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'%s'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavetxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ypred_W2V+GaussianNB_Context-Others'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'%s'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_test_sla' is not defined"
     ]
    }
   ],
   "source": [
    "np.savetxt('ytrue_W2V+GaussianNB_Context-Others', y_test_sla, fmt='%s')\n",
    "np.savetxt('ypred_W2V+GaussianNB_Context-Others', y_pred, fmt='%s')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
